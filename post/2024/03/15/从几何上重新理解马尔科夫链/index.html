<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>从几何上重新理解马尔科夫链 | Wenting Wang</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">从几何上重新理解马尔科夫链</span></h1>

<h2 class="date">2024/03/15</h2>
</div>

<main>
<h3 id="问题描述">问题描述</h3>
<p>状态沿着马尔可夫链（Markov chain）按照一定概率规则（转移矩阵）转移，下一步往哪转怎么转只和当前状态有关，和之前状态无关。某一条链：</p>
<p>$$S_1 \rightarrow S_2 \rightarrow S_2 \rightarrow S_1 \rightarrow &hellip;$$</p>
<p>一段时间后，经过<code>$S_1$</code>和<code>$S_2$</code>的频率（或概率）是多少？和转移依据的规则肯定有关系，那是什么关系？每条连经过两个状态的比例都相同吗？</p>
<h3 id="算一算">算一算</h3>
<p>状态向量（state vector）为一个概率向量（state vector）， 如：</p>
<p><code>$$\mathbf{w} = \begin{bmatrix} w_1 \\ w_2\end{bmatrix}= \begin{bmatrix} 0.9 \\ 0.1\end{bmatrix}$$</code></p>
<p>表示此时在状态<code>$S_1$</code>的概率为0.9，在状态<code>$S_2$</code>的概率为0.1。</p>
<p>转移矩阵（transition matrix）是一个随机矩阵（stochastic matrix）：</p>
<p><code>$$P =  \begin{bmatrix} p_{11} &amp; p_{21}\\ p_{12} &amp; p_{22} \end{bmatrix}=\begin{bmatrix} 0.8 &amp; 0.6\\ 0.2 &amp; 0.4 \end{bmatrix}$$</code></p>
<p><code>$p_{ij}$</code>表示从状态<code>$S_i$</code>到状态<code>$S_j$</code>的转移概率。</p>
<p><img src="/img/markov_chain.png" alt="markov_chain"></p>
<p>从任意一个向量出发，经过多次线性变换（linear transformation），如果转移矩阵是正则的（regular），总会收敛到一个平稳状态向量（steady-state vector）：</p>
<p><code>$$\mathbf{w} \leftarrow P\mathbf{w} = \begin{bmatrix} 0.8 &amp; 0.6\\ 0.2 &amp; 0.4 \end{bmatrix} \begin{bmatrix} 0.9 \\ 0.1  \end{bmatrix}=\begin{bmatrix} 0.78 \\ 0.22  \end{bmatrix} $$</code></p>
<p><code>$$\mathbf{w} \leftarrow P\mathbf{w} = \begin{bmatrix} 0.8 &amp; 0.6\\ 0.2 &amp; 0.4 \end{bmatrix} \begin{bmatrix} 0.78 \\ 0.22 \end{bmatrix}=\begin{bmatrix} 0.756 \\ 0.244  \end{bmatrix} $$</code></p>
<p><code>$$...$$</code></p>
<p><code>$$\mathbf{w} \leftarrow P\mathbf{w} = \begin{bmatrix} 0.8 &amp; 0.6\\ 0.2 &amp; 0.4 \end{bmatrix} \begin{bmatrix} 0.75 \\ 0.25 \end{bmatrix}=\begin{bmatrix} 0.75 \\ 0.25  \end{bmatrix} $$</code></p>
<p>此时，按照转移矩阵为<code>$P$</code>的马尔可夫链收敛至：</p>
<p><code>$$ \mathbf{w} =  \begin{bmatrix} 0.75 \\ 0.25  \end{bmatrix}$$</code></p>
<p>直观地说，马尔科夫链收敛至平稳后，进入一个状态的概率质量和从它出去的刚好相等，且对每一个状态来说都是如此。系统稳定地在状态间转移，即：</p>
<p><code>$$P\mathbf{w}=\mathbf{w}$$</code></p>
<p>此后一直保持平稳：</p>
<p><code>$$P^k\mathbf{w} = P^{k-1}\mathbf{w} =...=\mathbf{w} $$</code></p>
<h3 id="几何意义">几何意义</h3>
<p>从线性代数或几何上理解，空间经过多次线性变换（转移矩阵），最终收敛到一个方向，即的特征向量（eigenvector）的方向。空间上的所有点都会逐渐收敛到这个方向。</p>
<p><img src="/img/eigenvector.gif" alt="eigenvector"></p>
<p><strong>附 1</strong></p>
<p>Markov原文用的行向量，两种写法等价：</p>
<p><code>$$P \mathbf{w} \begin{bmatrix} p_{11} &amp; p_{21}\\ p_{12} &amp; p_{22} \end{bmatrix} \begin{bmatrix} w_1 \\ w_2  \end{bmatrix} $$</code></p>
<p><code>$$\mathbf{\pi} T =  \begin{bmatrix} w_1 &amp; w_2  \end{bmatrix} \begin{bmatrix} p_{11} &amp; p_{12}\\ p_{21} &amp; p_{22} \end{bmatrix} $$</code></p>
<p><strong>附 2</strong></p>
<p>由特征多项式（Charasteristic polynomial ）可判断<code>$P$</code>是否为正则（regular）。只有当转移矩阵为正则矩阵时，马尔科夫链才能收敛到平稳状态。如</p>
<p><code>$$P= \begin{bmatrix} 1 &amp; 0\\ 0 &amp; 1 \end{bmatrix} $$</code></p>
<p>每次线性变换，空间总是沿着<code>$x=y$</code>轴翻转，并不会收敛到稳定向量上。</p>
<p><strong>附 3</strong></p>
<p>因为从一个状态出去的概率总和为1，且每个状态都如此。可证有一个特征值为1。</p>
<p><code>$$P \mathbf{w} = \lambda \mathbf{w}$$</code></p>
<p><code>$$(P-\lambda I)\mathbf{w} = 0$$</code></p>
<p><code>$$det(P-\lambda I) =0$$</code></p>
<p>每列和需要为1，则<code>$\lambda$</code>必为1。</p>
<p>也可以用特征多项式（Characteristic polynomial ）证明。</p>
<p><strong>附 4</strong></p>
<p>传说Markov发明这种链是为了反驳“中心极限定理必须在变量独立时才成立”。变量不独立，条件分布，依然收敛。</p>
<p><strong>附 5</strong></p>
<p>Python code</p>
<pre><code class="language-python3">import numpy as np

# Define the transition matrix
P = np.array([[0.8, 0.6], [0.2, 0.4]])

# Initial state probability distribution
w = np.array([0.9, 0.1])

# To store the state probabilities over iterations
state_probabilities = [w.tolist()]

# Perform several iterations
for _ in range(10):
    w = np.dot(P, w)
    state_probabilities.append(w.tolist())

state_probabilities
</code></pre>
<p><strong>参考资料</strong></p>
<p><a href="https://visualize-it.github.io/linear_transformations/simulation.html">Linear Transformations Visualizer</a></p>
<p><a href="https://www.youtube.com/watch?v=2AImkYS1KpM">Markov Chains MADE EASY | Linear Algebra APPLICATIONS</a></p>

</main>

  <footer>
  <script defer src="//yihui.org/js/math-code.js"></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script defer src="//yihui.org/js/center-img.js"></script>

  
  <hr/>
  © <a href="https://wenting-wang.github.io/">Wenting Wang</a> 2019 &ndash; 2024
  
  </footer>
  </body>
</html>

