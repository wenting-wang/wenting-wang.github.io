<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>缺失值的处理 | Wenting Wang</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">缺失值的处理</span></h1>

<h2 class="date">2022/10/23</h2>
</div>

<main>
<p>缺失值处理有时候甚至比机器学习模型本身更重要，因为数据质量决定了预测精度上限，而模型只是去逼近这个上限。</p>
<p>但是Missing Data Imputation是个很大的问题，具体情况具体分析，很难一概而论。涉及行业背景、特征间的关系、数据缺失的原因（随机缺失；非随机缺失；完全随机缺失，即只有一部分是可以通过统计方法处理的，另一些只能靠重新采集数据）、缺失值处理方法（少的话直接删掉，或者简单填充，连续数用均值，离散数用众数，也可以建模用统计或机器学习方法填充，也可以不用管，有的模型如XGBoost会自动处理缺失值，对流数据处理方法又有不同），还有其他诸多因素。</p>
<p>一些参考文献和包：</p>
<ol>
<li>文献</li>
</ol>
<p>很全面的综述，对于分类问题怎么处理缺失值：García-Laencina, Pedro J., José-Luis Sancho-Gómez, and Aníbal R. Figueiras-Vidal. &ldquo;Pattern classification with missing data: a review.&rdquo; Neural Computing and Applications 19.2 (2010): 263-282.</p>
<p>随机森林分类问题下缺失值的处理：Overcoming Missing Values in A Random Forest Classifier, By Alok, GUPTA</p>
<p>简单介绍特征工程（缺失值处理可以看做特征工程的一部分）：Discover Feature Engineering, How to Engineer Features and How to Get Good at It</p>
<ol start="2">
<li>常用工具包</li>
</ol>
<p>fancyimpute (<a href="https://github.com/iskandr/fancyimpute">https://github.com/iskandr/fancyimpute</a>)</p>
<p>multiple-imputation (<a href="http://www.stefvanbuuren.nl/mi/index.html">http://www.stefvanbuuren.nl/mi/index.html</a>)</p>

</main>

  <footer>
  <script defer src="//yihui.org/js/math-code.js"></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script defer src="//yihui.org/js/center-img.js"></script>

  
  <hr/>
  © <a href="https://wenting-wang.github.io/">Wenting Wang</a> 2019 &ndash; 2024
  
  </footer>
  </body>
</html>

